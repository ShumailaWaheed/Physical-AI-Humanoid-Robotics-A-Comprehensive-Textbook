---
title: NVIDIA Isaac Sim Practical Examples
---

import useBaseUrl from '@docusaurus/useBaseUrl';

# Module 3: NVIDIA Isaac Sim Practical Examples

This chapter provides hands-on examples using NVIDIA Isaac Sim to demonstrate fundamental robotics tasks: perception, navigation, and manipulation. These examples utilize Isaac Sim's Python API, built on `omni.isaac.core`, to interact with the simulation environment.

:::info Prerequisite
Ensure you have NVIDIA Isaac Sim installed and configured. These examples assume basic familiarity with launching Isaac Sim and accessing its Python environment.
:::

## Example 1: Basic Perception - Camera Image Capture

This example demonstrates how to spawn a simple camera sensor in Isaac Sim, attach it to a robot or a fixed location, and capture images. This is foundational for any AI perception task.

**Goal:** Capture an RGB image from a simulated camera.

```python
import omni.isaac.core as ic
from omni.isaac.core.objects import DynamicCuboid
from omni.isaac.synthetic_utils import SyntheticDataHelper
import numpy as np

def run_camera_example():
    # Initialize Isaac Sim
    kit = ic.acquire_app_interface()
    kit.update()

    # Create a World object for easy simulation management
    world = ic.World(stage_units_in_meters=1.0)
    world.scene.add_default_ground_plane()

    # Add a simple object to the scene
    cube = world.scene.add(DynamicCuboid(
        prim_path="/World/cube",
        name="cube",
        position=np.array([0.0, 0.0, 0.5]),
        size=1.0,
        color=np.array([1.0, 0.0, 0.0]))
    )

    # Create a camera (in USD, a camera is a prim)
    camera_prim_path = "/World/camera"
    camera = ic.utils.numpy.add_camera(
        prim_path=camera_prim_path,
        position=np.array([2.0, 2.0, 1.5]),
        target=np.array([0.0, 0.0, 0.5])
    )

    # Enable data collection from the camera
    sd_helper = SyntheticDataHelper()
    sd_helper.initialize(["rgb"])

    world.reset()

    # Simulate for a few frames to allow camera to render
    for _ in range(10):
        world.step(render=True)
        kit.update()

    # Capture RGB image
    rgb_data = sd_helper.get_groundtruth(["rgb"], camera_prim_path)
    rgb_image = rgb_data["rgb"] # This will be a numpy array

    print(f"Captured RGB image with shape: {rgb_image.shape}")
    # You can save this image using libraries like PIL (Pillow)
    # from PIL import Image
    # img = Image.fromarray(rgb_image)
    # img.save("captured_image.png")
    print("Image capture successful!")

    # Clean up
    world.clear_instance()
    kit.shutdown()

if __name__ == "__main__":
    run_camera_example()
```

**Explanation:**
-   `omni.isaac.core`: The main library for interacting with Isaac Sim.
-   `ic.World`: Manages the simulation environment, including physics and time steps.
-   `add_default_ground_plane()`: Adds a ground plane for objects to rest on.
-   `DynamicCuboid`: Creates a primitive cube object.
-   `ic.utils.numpy.add_camera`: Helper function to create a camera prim and set its position/target.
-   `SyntheticDataHelper`: Essential for enabling and capturing ground truth data (like RGB, depth, segmentation) from sensors.
-   `world.step(render=True)`: Advances the simulation by one step and renders the scene.

<img alt="Isaac Sim Camera View Screenshot" src={useBaseUrl('/img/isaac_sim_camera_view.png')} />

**Simulation Screenshot Placeholder:** A screenshot from Isaac Sim showing the camera's perspective of the cube on the ground plane.

**Exercise:** Modify the example to add multiple cubes of different colors and positions. Can you capture a depth image instead of RGB?

## Example 2: Simple Navigation - Moving a Differential Drive Robot

This example demonstrates controlling a basic differential drive robot in Isaac Sim. We'll use direct velocity commands to make the robot move.

**Goal:** Make a differential drive robot move forward, turn, and stop.

```python
import omni.isaac.core as ic
from omni.isaac.franka.controllers import RMPFlowController # Placeholder, use a generic diff drive controller or direct interface
from omni.isaac.universal_robots.ur10 import UR10 # Placeholder, use a diff drive robot
from omni.isaac.core.articulations import Articulation
import numpy as np
import time

def run_navigation_example():
    kit = ic.acquire_app_interface()
    kit.update()

    world = ic.World(stage_units_in_meters=1.0)
    world.scene.add_default_ground_plane()

    # Add a differential drive robot (e.g., a simple mobile base)
    # NOTE: Replace with actual differential drive robot loading if available
    # This is a conceptual placeholder. You would typically load a USD model.
    robot_prim_path = "/World/SimpleDifferentialDriveRobot"
    try:
        robot = Articulation(prim_path=robot_prim_path, name="my_diff_drive_robot")
        world.scene.add(robot)
    except Exception as e:
        print(f"Could not add differential drive robot. Ensure USD is available: {e}")
        print("Creating a placeholder Articulation instead.")
        robot = Articulation(prim_path=robot_prim_path, name="my_diff_drive_robot")
        world.scene.add(robot)

    world.reset()

    # Get articulation API to control joints (conceptual for diff drive wheels)
    # In a real diff drive robot, you'd get specific wheel joints
    # For this conceptual example, we'll simulate setting linear/angular velocity

    print("Robot moving forward...")
    for _ in range(50): # Move forward for 50 steps
        # In a real diff drive, you'd set velocities for left/right wheels
        # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[vel, vel])
        # For this conceptual example, we print and simulate time
        print("Simulating forward motion...")
        world.step(render=True)
        kit.update()

    print("Robot turning left...")
    for _ in range(25): # Turn left for 25 steps
        # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[-vel, vel])
        print("Simulating turn...")
        world.step(render=True)
        kit.update()

    print("Robot stopping...")
    # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[0.0, 0.0])
    for _ in range(10):
        print("Simulating stop...")
        world.step(render=True)
        kit.update()

    print("Navigation example complete!")

    world.clear_instance()
    kit.shutdown()

if __name__ == "__main__":
    run_navigation_example()
```

**Explanation:**
-   `Articulation`: Represents a multi-body robot with joints.
-   The actual control of a differential drive robot involves setting velocities for its wheel joints. The provided code is a conceptual placeholder as a generic differential drive robot is not directly available via a simple `add` function in `omni.isaac.core` without a specific USD model.
-   In a real scenario, you would load a differential drive robot's USD and then use `robot.get_dof_properties()` and `robot.set_joint_velocities()` to control it.

<img alt="Isaac Sim Differential Drive Robot" src={useBaseUrl('/img/isaac_sim_diff_drive.png')} />

**Simulation Screenshot Placeholder:** A screenshot of a differential drive robot (e.g., a TurtleBot or a simpler mobile base) in Isaac Sim moving through an environment.

**Exercise:** Research how to load a specific differential drive robot USD model (e.g., the `carter` robot from Isaac Sim's asset library). Implement the actual joint velocity control for its wheels to make it drive in a square.

## Example 3: Simple Manipulation - Moving a Robotic Arm End-Effector

This example focuses on basic manipulation, specifically controlling the end-effector of a robotic arm to reach a target pose using inverse kinematics (IK).

**Goal:** Move a robotic arm's end-effector to a specified target position.

```python
import omni.isaac.core as ic
from omni.isaac.franka import Franka
from omni.isaac.core.utils.nucleus import get_assets_root_path
from omni.isaac.core.articulations import Articulation
import numpy as np
import asyncio

# NOTE: Isaac Sim's API often requires being run in an async loop
# For simplicity, we'll use a sync approach if possible, or adapt.

async def run_manipulation_example():
    kit = ic.acquire_app_interface()
    kit.update()

    world = ic.World(stage_units_in_meters=1.0)
    world.scene.add_default_ground_plane()

    assets_root_path = get_assets_root_path()
    if assets_root_path is None:
        print("Could not find Isaac Sim assets root. Please ensure Nucleus is configured.")
        kit.shutdown()
        return

    franka_usd_path = assets_root_path + "/Isaac/Robots/Franka/franka_alt_fingers.usd"

    # Add Franka robot
    franka = world.scene.add(Franka(
        prim_path="/World/Franka",
        name="franka",
        usd_path=franka_usd_path,
        position=np.array([0.0, 0.0, 0.0])
    ))

    world.reset()

    # Wait for the physics to settle
    await world.stop()
    await world.play()
    for _ in range(50): # Allow robot to settle to initial pose
        await world.render()
        await kit.update()

    # Get the controller for Franka (e.g., RMPFlow for reaching poses)
    # NOTE: RMPFlowController is typically used for this.
    # For this simplified example, we'll conceptualize target setting.
    # In a full example, you'd acquire an RMPFlowController and set its target.
    # from omni.isaac.franka.controllers import RMPFlowController
    # franka_controller = RMPFlowController(name="rmp_controller", robot_articulation=franka)

    target_position = np.array([0.5, 0.3, 0.8]) # A target position in meters (x, y, z)
    print(f"Attempting to move Franka end-effector to: {target_position}")

    # Conceptual move command (replace with actual controller logic)
    # franka_controller.set_end_effector_target(target_position, target_orientation)
    # In a real scenario, you'd loop and call the controller's compute_actions
    # and then apply those actions (joint positions/velocities) to the robot.

    for i in range(200): # Simulate movement over time
        # if franka_controller.is_at_target():
        #     print("Reached target!")
        #     break
        # actions = franka_controller.compute_actions(current_joint_positions, current_joint_velocities)
        # franka.apply_action(actions)
        if i % 50 == 0:
            print(f"Simulating movement towards target. Step {i}...")
        await world.render()
        await kit.update()

    print("Manipulation example complete!")

    world.clear_instance()
    kit.shutdown()

if __name__ == "__main__":
    # Isaac Sim apps often need to be run with asyncio
    asyncio.run(run_manipulation_example())
```

**Explanation:**
-   `Franka`: A pre-built robot model available in Isaac Sim.
-   `get_assets_root_path()`: Helps locate the default Isaac Sim assets.
-   `world.reset()`, `world.play()`, `world.render()`: Control the simulation state and rendering.
-   The manipulation of robotic arms typically involves advanced controllers like `RMPFlowController` which handle inverse kinematics and collision avoidance to move the end-effector to a desired pose (position and orientation). The provided code outlines the conceptual steps.

<img alt="Isaac Sim Franka Arm Manipulation" src={useBaseUrl('/img/isaac_sim_franka_manipulation.png')} />

**Simulation Screenshot Placeholder:** A screenshot from Isaac Sim showing the Franka Emika Panda robot arm reaching towards a target or grasping an object.

**Exercise:** Integrate the `RMPFlowController` from `omni.isaac.franka.controllers` into the example. Define a specific target position and orientation for the end-effector and observe the robot moving to that pose.

## Viva Questions & Answers

1.  **Q:** What Python module is primarily used to interact with the Isaac Sim environment?
    **A:** `omni.isaac.core`.
    **Roman Urdu:** Isaac Sim environment ke sath interact karne ke liye bunyadi taur par kaun sa Python module istemal hota hai? `omni.isaac.core`.

2.  **Q:** How do you enable and capture ground truth data from sensors like cameras in Isaac Sim?
    **A:** Using the `SyntheticDataHelper` class.
    **Roman Urdu:** Isaac Sim mein sensors jaise cameras se ground truth data ko kaise enable aur capture kiya jata hai? `SyntheticDataHelper` class ka istemal karte hue.

3.  **Q:** What is an `Articulation` object used for in `omni.isaac.core`?
    **A:** It represents a multi-body robot with joints, allowing for control over its kinematic and dynamic properties.
    **Roman Urdu:** `omni.isaac.core` mein `Articulation` object kis maqsad ke liye istemal hota hai? Yeh joints ke sath ek multi-body robot ko represent karta hai, jo uski kinematic aur dynamic properties par control ki ijazat deta hai.

4.  **Q:** What is the common approach for controlling a robotic arm's end-effector to reach a target pose in Isaac Sim?
    **A:** Using an Inverse Kinematics (IK) controller, such as `RMPFlowController`, to compute joint commands.
    **Roman Urdu:** Isaac Sim mein robotic arm ke end-effector ko target pose tak pohnchane ke liye aam tareeqa kya hai? Inverse Kinematics (IK) controller, jaise `RMPFlowController`, ka istemal karna joint commands ko compute karne ke liye.

5.  **Q:** Why is it important to use `world.step(render=True)` or `await world.render()` in Isaac Sim scripts?
    **A:** These calls advance the simulation by one step and ensure that the scene is rendered, allowing sensor data to be captured and visual updates to occur.
    **Roman Urdu:** Isaac Sim scripts mein `world.step(render=True)` ya `await world.render()` ka istemal karna kyun zaroori hai? Yeh calls simulation ko ek step aage badhate hain aur yeh yaqeeni banate hain ke scene render ho, jis se sensor data capture kiya ja sake aur visual updates ho saken.
