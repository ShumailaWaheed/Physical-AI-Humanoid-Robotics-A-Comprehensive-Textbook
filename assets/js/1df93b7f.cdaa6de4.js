"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[4583],{5579:(e,t,o)=>{o.r(t),o.d(t,{default:()=>b});var s=o(4164),n=o(8774),a=o(4586),i=o(1656),r=o(1107);const l={features:"features_t9lD",row:"row_kvGa",col:"col_NUvg","col--3":"col--3_KYxR",neonCard:"neonCard_tEVm",cardContent:"cardContent_fLx7",particles:"particles_YpsI",moveParticles:"moveParticles_R59L"};var c=o(4848);const d=[{title:"Physical AI Foundations",description:(0,c.jsx)(c.Fragment,{children:"Understand AI in the physical world. Learn embodied intelligence, perception, decision making, and how AI interacts with physics-based robotic systems."})},{title:"Humanoid Robot Middleware (ROS 2)",description:(0,c.jsx)(c.Fragment,{children:"Learn ROS 2 architecture, nodes, topics, and services to build a robotic nervous system capable of controlling humanoid motion in simulation and labs."})},{title:"NVIDIA Isaac & VLA Capstone",description:(0,c.jsx)(c.Fragment,{children:"Work on vision-language-action (VLA), speech-to-action, path planning and object manipulation using high-fidelity robotics simulators + AI agents."})},{title:"Real-World Autonomy",description:(0,c.jsx)(c.Fragment,{children:"Build autonomous humanoids that receive natural commands, plan multi-step tasks, avoid obstacles and manipulate objects using sensors like cameras, LiDAR, and IMUs."})}];function h({title:e,description:t}){return(0,c.jsxs)("div",{className:(0,s.A)("col col--3",l.neonCard,"group"),children:[(0,c.jsxs)("div",{className:l.cardContent,children:[(0,c.jsx)(r.A,{as:"h3",children:e}),(0,c.jsx)("p",{children:t})]}),(0,c.jsx)("div",{className:l.particles})," "]})}function m(){return(0,c.jsx)("section",{className:l.features,children:(0,c.jsx)("div",{className:"container",children:(0,c.jsx)("div",{className:l.row,children:d.map((e,t)=>(0,c.jsx)(h,{title:e.title,description:e.description},t))})})})}const u={heroBanner:"heroBanner_qdFl",heroImage:"heroImage_xZN7",float:"float_x2Lw",dotWrap:"dotWrap_zSNZ",dot:"dot_K917",dotMove:"dotMove_a3wz",hero__title:"hero__title_sobY",hero__subtitle:"hero__subtitle_AUTZ",hoverBtn:"hoverBtn_Vz7Z"};function p(){const{siteConfig:e}=(0,a.A)();return(0,c.jsxs)("header",{className:(0,s.A)("hero hero--primary",u.heroBanner),style:{backgroundImage:"url('/img/hero-01.jpg')",backgroundSize:"cover",backgroundPosition:"center"},children:[(0,c.jsxs)("div",{className:u.robotWrap,children:[(0,c.jsx)("div",{className:u.robot,style:{top:"10%",left:"15%"}}),(0,c.jsx)("div",{className:u.robot,style:{top:"25%",left:"70%"}}),(0,c.jsx)("div",{className:u.robot,style:{top:"50%",left:"40%"}}),(0,c.jsx)("div",{className:u.robot,style:{top:"65%",left:"20%"}}),(0,c.jsx)("div",{className:u.robot,style:{top:"80%",left:"60%"}})]}),(0,c.jsxs)("div",{className:"container",children:[(0,c.jsx)(r.A,{as:"h1",className:"hero__title",children:"Physical AI & Humanoid Robotics \u26a1"}),(0,c.jsx)("p",{className:"hero__subtitle",children:"Learn embodied intelligence, robot perception, motion planning and AI-driven physical autonomy using ROS 2, Gazebo, Unity and NVIDIA Isaac."}),(0,c.jsx)("div",{className:u.buttons,children:(0,c.jsx)(n.A,{className:(0,s.A)("button button--secondary button--lg",u.hoverBtn),to:"/docs/intro",children:"Start Learning \ud83d\ude80"})})]})]})}function b(){const{siteConfig:e}=(0,a.A)();return(0,c.jsxs)(i.A,{title:`Welcome to ${e.title}`,description:"AI systems operating in the real physical world. Learn robotics + AI agents + humanoid autonomy.",children:[(0,c.jsx)(p,{}),(0,c.jsx)("main",{style:{background:"#01040f",paddingTop:"30px"},children:(0,c.jsx)(m,{})})]})}}}]);