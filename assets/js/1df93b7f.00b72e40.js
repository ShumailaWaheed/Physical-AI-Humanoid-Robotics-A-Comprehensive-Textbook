"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[4583],{5579:(e,s,n)=>{n.r(s),n.d(s,{default:()=>g});var a=n(4164),o=n(8774),t=n(4586),i=n(1656),r=n(1107);const c={features:"features_t9lD",row:"row_kvGa",col:"col_NUvg","col--3":"col--3_KYxR",neonCard:"neonCard_tEVm",cardContent:"cardContent_fLx7",particles:"particles_YpsI",moveParticles:"moveParticles_R59L"};var l=n(4848);const d=[{title:"Physical AI Foundations",description:(0,l.jsx)(l.Fragment,{children:"Understand AI in the physical world. Learn embodied intelligence, perception, decision making, and how AI interacts with physics-based robotic systems."})},{title:"Humanoid Robot Middleware (ROS 2)",description:(0,l.jsx)(l.Fragment,{children:"Learn ROS 2 architecture, nodes, topics, and services to build a robotic nervous system capable of controlling humanoid motion in simulation and labs."})},{title:"NVIDIA Isaac & VLA Capstone",description:(0,l.jsx)(l.Fragment,{children:"Work on vision-language-action (VLA), speech-to-action, path planning and object manipulation using high-fidelity robotics simulators + AI agents."})},{title:"Real-World Autonomy",description:(0,l.jsx)(l.Fragment,{children:"Build autonomous humanoids that receive natural commands, plan multi-step tasks, avoid obstacles and manipulate objects using sensors like cameras, LiDAR, and IMUs."})}];function h({title:e,description:s}){return(0,l.jsxs)("div",{className:(0,a.A)("col col--3",c.neonCard,"group"),children:[(0,l.jsxs)("div",{className:c.cardContent,children:[(0,l.jsx)(r.A,{as:"h3",children:e}),(0,l.jsx)("p",{children:s})]}),(0,l.jsx)("div",{className:c.particles})," "]})}function m(){return(0,l.jsx)("section",{className:c.features,children:(0,l.jsx)("div",{className:"container",children:(0,l.jsx)("div",{className:c.row,children:d.map((e,s)=>(0,l.jsx)(h,{title:e.title,description:e.description},s))})})})}const p={heroBanner:"heroBanner_qdFl",heroImage:"heroImage_xZN7",float:"float_x2Lw",dotWrap:"dotWrap_zSNZ",dot:"dot_K917",dotMove:"dotMove_a3wz",hero__title:"hero__title_sobY",hero__subtitle:"hero__subtitle_AUTZ",hoverBtn:"hoverBtn_Vz7Z"};function u(){const{siteConfig:e}=(0,t.A)();return(0,l.jsxs)("header",{className:(0,a.A)("hero hero--primary",p.heroBanner),style:{backgroundImage:"url('/img/hero.jpg')",backgroundSize:"cover",backgroundPosition:"center"},children:[(0,l.jsx)("img",{src:"/img/robot.png",className:p.heroImage}),(0,l.jsxs)("div",{className:"dotWrap",children:[(0,l.jsx)("span",{className:"dot",children:"\u2728"}),(0,l.jsx)("span",{className:"dot",children:"\u2726"}),(0,l.jsx)("span",{className:"dot",children:"\u273a"}),(0,l.jsx)("span",{className:"dot",children:"\u2739"}),(0,l.jsx)("span",{className:"dot",children:"\u2727"}),(0,l.jsx)("span",{className:"dot",children:"\u2737"})]}),(0,l.jsxs)("div",{className:"container",children:[(0,l.jsx)(r.A,{as:"h1",className:"hero__title",children:"Physical AI & Humanoid Robotics \u26a1"}),(0,l.jsx)("p",{className:"hero__subtitle",children:"Learn embodied intelligence, robot perception, motion planning and AI-driven physical autonomy using ROS 2, Gazebo, Unity and NVIDIA Isaac."}),(0,l.jsx)("div",{className:p.buttons,children:(0,l.jsx)(o.A,{className:(0,a.A)("button button--secondary button--lg",p.hoverBtn),to:"/docs/intro",children:"Start Learning \ud83d\ude80"})})]})]})}function g(){const{siteConfig:e}=(0,t.A)();return(0,l.jsxs)(i.A,{title:`Welcome to ${e.title}`,description:"AI systems operating in the real physical world. Learn robotics + AI agents + humanoid autonomy.",children:[(0,l.jsx)(u,{}),(0,l.jsx)("main",{style:{background:"#01040f",paddingTop:"30px"},children:(0,l.jsx)(m,{})})]})}}}]);