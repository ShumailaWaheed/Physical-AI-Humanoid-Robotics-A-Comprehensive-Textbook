"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[2582],{5851:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module3-NVIDIA Isaac/module3_examples","title":"NVIDIA Isaac Sim Practical Examples","description":"This chapter provides hands-on examples using NVIDIA Isaac Sim to demonstrate fundamental robotics tasks: perception, navigation, and manipulation. These examples utilize Isaac Sim\'s Python API, built on omni.isaac.core, to interact with the simulation environment.","source":"@site/docs/module3-NVIDIA Isaac/module3_examples.mdx","sourceDirName":"module3-NVIDIA Isaac","slug":"/module3-NVIDIA Isaac/module3_examples","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module3-NVIDIA Isaac/module3_examples","draft":false,"unlisted":false,"editUrl":"https://github.com/ShumailaWaheed/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/edit/main/docs/module3-NVIDIA Isaac/module3_examples.mdx","tags":[],"version":"current","frontMatter":{"title":"NVIDIA Isaac Sim Practical Examples"},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Advanced Topics & Optimization","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module3-NVIDIA Isaac/module3_advanced"},"next":{"title":"NVIDIA Isaac Platform Overview","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module3-NVIDIA Isaac/module3_overview"}}');var o=a(4848),t=a(8453),r=a(6025);const s={title:"NVIDIA Isaac Sim Practical Examples"},l="Module 3: NVIDIA Isaac Sim Practical Examples",c={},d=[{value:"Example 1: Basic Perception - Camera Image Capture",id:"example-1-basic-perception---camera-image-capture",level:2},{value:"Example 2: Simple Navigation - Moving a Differential Drive Robot",id:"example-2-simple-navigation---moving-a-differential-drive-robot",level:2},{value:"Example 3: Simple Manipulation - Moving a Robotic Arm End-Effector",id:"example-3-simple-manipulation---moving-a-robotic-arm-end-effector",level:2},{value:"Viva Questions &amp; Answers",id:"viva-questions--answers",level:2}];function m(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"module-3-nvidia-isaac-sim-practical-examples",children:"Module 3: NVIDIA Isaac Sim Practical Examples"})}),"\n",(0,o.jsxs)(n.p,{children:["This chapter provides hands-on examples using NVIDIA Isaac Sim to demonstrate fundamental robotics tasks: perception, navigation, and manipulation. These examples utilize Isaac Sim's Python API, built on ",(0,o.jsx)(n.code,{children:"omni.isaac.core"}),", to interact with the simulation environment."]}),"\n",(0,o.jsx)(n.admonition,{title:"Prerequisite",type:"info",children:(0,o.jsx)(n.p,{children:"Ensure you have NVIDIA Isaac Sim installed and configured. These examples assume basic familiarity with launching Isaac Sim and accessing its Python environment."})}),"\n",(0,o.jsx)(n.h2,{id:"example-1-basic-perception---camera-image-capture",children:"Example 1: Basic Perception - Camera Image Capture"}),"\n",(0,o.jsx)(n.p,{children:"This example demonstrates how to spawn a simple camera sensor in Isaac Sim, attach it to a robot or a fixed location, and capture images. This is foundational for any AI perception task."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Goal:"})," Capture an RGB image from a simulated camera."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import omni.isaac.core as ic\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.synthetic_utils import SyntheticDataHelper\nimport numpy as np\n\ndef run_camera_example():\n    # Initialize Isaac Sim\n    kit = ic.acquire_app_interface()\n    kit.update()\n\n    # Create a World object for easy simulation management\n    world = ic.World(stage_units_in_meters=1.0)\n    world.scene.add_default_ground_plane()\n\n    # Add a simple object to the scene\n    cube = world.scene.add(DynamicCuboid(\n        prim_path="/World/cube",\n        name="cube",\n        position=np.array([0.0, 0.0, 0.5]),\n        size=1.0,\n        color=np.array([1.0, 0.0, 0.0]))\n    )\n\n    # Create a camera (in USD, a camera is a prim)\n    camera_prim_path = "/World/camera"\n    camera = ic.utils.numpy.add_camera(\n        prim_path=camera_prim_path,\n        position=np.array([2.0, 2.0, 1.5]),\n        target=np.array([0.0, 0.0, 0.5])\n    )\n\n    # Enable data collection from the camera\n    sd_helper = SyntheticDataHelper()\n    sd_helper.initialize(["rgb"])\n\n    world.reset()\n\n    # Simulate for a few frames to allow camera to render\n    for _ in range(10):\n        world.step(render=True)\n        kit.update()\n\n    # Capture RGB image\n    rgb_data = sd_helper.get_groundtruth(["rgb"], camera_prim_path)\n    rgb_image = rgb_data["rgb"] # This will be a numpy array\n\n    print(f"Captured RGB image with shape: {rgb_image.shape}")\n    # You can save this image using libraries like PIL (Pillow)\n    # from PIL import Image\n    # img = Image.fromarray(rgb_image)\n    # img.save("captured_image.png")\n    print("Image capture successful!")\n\n    # Clean up\n    world.clear_instance()\n    kit.shutdown()\n\nif __name__ == "__main__":\n    run_camera_example()\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"omni.isaac.core"}),": The main library for interacting with Isaac Sim."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ic.World"}),": Manages the simulation environment, including physics and time steps."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"add_default_ground_plane()"}),": Adds a ground plane for objects to rest on."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"DynamicCuboid"}),": Creates a primitive cube object."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"ic.utils.numpy.add_camera"}),": Helper function to create a camera prim and set its position/target."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"SyntheticDataHelper"}),": Essential for enabling and capturing ground truth data (like RGB, depth, segmentation) from sensors."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"world.step(render=True)"}),": Advances the simulation by one step and renders the scene."]}),"\n"]}),"\n",(0,o.jsx)("img",{alt:"Isaac Sim Camera View Screenshot",src:(0,r.Ay)("/img/isaac_sim_camera_view.png")}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Simulation Screenshot Placeholder:"})," A screenshot from Isaac Sim showing the camera's perspective of the cube on the ground plane."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise:"})," Modify the example to add multiple cubes of different colors and positions. Can you capture a depth image instead of RGB?"]}),"\n",(0,o.jsx)(n.h2,{id:"example-2-simple-navigation---moving-a-differential-drive-robot",children:"Example 2: Simple Navigation - Moving a Differential Drive Robot"}),"\n",(0,o.jsx)(n.p,{children:"This example demonstrates controlling a basic differential drive robot in Isaac Sim. We'll use direct velocity commands to make the robot move."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Goal:"})," Make a differential drive robot move forward, turn, and stop."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import omni.isaac.core as ic\nfrom omni.isaac.franka.controllers import RMPFlowController # Placeholder, use a generic diff drive controller or direct interface\nfrom omni.isaac.universal_robots.ur10 import UR10 # Placeholder, use a diff drive robot\nfrom omni.isaac.core.articulations import Articulation\nimport numpy as np\nimport time\n\ndef run_navigation_example():\n    kit = ic.acquire_app_interface()\n    kit.update()\n\n    world = ic.World(stage_units_in_meters=1.0)\n    world.scene.add_default_ground_plane()\n\n    # Add a differential drive robot (e.g., a simple mobile base)\n    # NOTE: Replace with actual differential drive robot loading if available\n    # This is a conceptual placeholder. You would typically load a USD model.\n    robot_prim_path = "/World/SimpleDifferentialDriveRobot"\n    try:\n        robot = Articulation(prim_path=robot_prim_path, name="my_diff_drive_robot")\n        world.scene.add(robot)\n    except Exception as e:\n        print(f"Could not add differential drive robot. Ensure USD is available: {e}")\n        print("Creating a placeholder Articulation instead.")\n        robot = Articulation(prim_path=robot_prim_path, name="my_diff_drive_robot")\n        world.scene.add(robot)\n\n    world.reset()\n\n    # Get articulation API to control joints (conceptual for diff drive wheels)\n    # In a real diff drive robot, you\'d get specific wheel joints\n    # For this conceptual example, we\'ll simulate setting linear/angular velocity\n\n    print("Robot moving forward...")\n    for _ in range(50): # Move forward for 50 steps\n        # In a real diff drive, you\'d set velocities for left/right wheels\n        # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[vel, vel])\n        # For this conceptual example, we print and simulate time\n        print("Simulating forward motion...")\n        world.step(render=True)\n        kit.update()\n\n    print("Robot turning left...")\n    for _ in range(25): # Turn left for 25 steps\n        # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[-vel, vel])\n        print("Simulating turn...")\n        world.step(render=True)\n        kit.update()\n\n    print("Robot stopping...")\n    # robot.set_joint_velocities(joint_indices=[left_wheel_idx, right_wheel_idx], velocities=[0.0, 0.0])\n    for _ in range(10):\n        print("Simulating stop...")\n        world.step(render=True)\n        kit.update()\n\n    print("Navigation example complete!")\n\n    world.clear_instance()\n    kit.shutdown()\n\nif __name__ == "__main__":\n    run_navigation_example()\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"Articulation"}),": Represents a multi-body robot with joints."]}),"\n",(0,o.jsxs)(n.li,{children:["The actual control of a differential drive robot involves setting velocities for its wheel joints. The provided code is a conceptual placeholder as a generic differential drive robot is not directly available via a simple ",(0,o.jsx)(n.code,{children:"add"})," function in ",(0,o.jsx)(n.code,{children:"omni.isaac.core"})," without a specific USD model."]}),"\n",(0,o.jsxs)(n.li,{children:["In a real scenario, you would load a differential drive robot's USD and then use ",(0,o.jsx)(n.code,{children:"robot.get_dof_properties()"})," and ",(0,o.jsx)(n.code,{children:"robot.set_joint_velocities()"})," to control it."]}),"\n"]}),"\n",(0,o.jsx)("img",{alt:"Isaac Sim Differential Drive Robot",src:(0,r.Ay)("/img/isaac_sim_diff_drive.png")}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Simulation Screenshot Placeholder:"})," A screenshot of a differential drive robot (e.g., a TurtleBot or a simpler mobile base) in Isaac Sim moving through an environment."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise:"})," Research how to load a specific differential drive robot USD model (e.g., the ",(0,o.jsx)(n.code,{children:"carter"})," robot from Isaac Sim's asset library). Implement the actual joint velocity control for its wheels to make it drive in a square."]}),"\n",(0,o.jsx)(n.h2,{id:"example-3-simple-manipulation---moving-a-robotic-arm-end-effector",children:"Example 3: Simple Manipulation - Moving a Robotic Arm End-Effector"}),"\n",(0,o.jsx)(n.p,{children:"This example focuses on basic manipulation, specifically controlling the end-effector of a robotic arm to reach a target pose using inverse kinematics (IK)."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Goal:"})," Move a robotic arm's end-effector to a specified target position."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import omni.isaac.core as ic\nfrom omni.isaac.franka import Franka\nfrom omni.isaac.core.utils.nucleus import get_assets_root_path\nfrom omni.isaac.core.articulations import Articulation\nimport numpy as np\nimport asyncio\n\n# NOTE: Isaac Sim\'s API often requires being run in an async loop\n# For simplicity, we\'ll use a sync approach if possible, or adapt.\n\nasync def run_manipulation_example():\n    kit = ic.acquire_app_interface()\n    kit.update()\n\n    world = ic.World(stage_units_in_meters=1.0)\n    world.scene.add_default_ground_plane()\n\n    assets_root_path = get_assets_root_path()\n    if assets_root_path is None:\n        print("Could not find Isaac Sim assets root. Please ensure Nucleus is configured.")\n        kit.shutdown()\n        return\n\n    franka_usd_path = assets_root_path + "/Isaac/Robots/Franka/franka_alt_fingers.usd"\n\n    # Add Franka robot\n    franka = world.scene.add(Franka(\n        prim_path="/World/Franka",\n        name="franka",\n        usd_path=franka_usd_path,\n        position=np.array([0.0, 0.0, 0.0])\n    ))\n\n    world.reset()\n\n    # Wait for the physics to settle\n    await world.stop()\n    await world.play()\n    for _ in range(50): # Allow robot to settle to initial pose\n        await world.render()\n        await kit.update()\n\n    # Get the controller for Franka (e.g., RMPFlow for reaching poses)\n    # NOTE: RMPFlowController is typically used for this.\n    # For this simplified example, we\'ll conceptualize target setting.\n    # In a full example, you\'d acquire an RMPFlowController and set its target.\n    # from omni.isaac.franka.controllers import RMPFlowController\n    # franka_controller = RMPFlowController(name="rmp_controller", robot_articulation=franka)\n\n    target_position = np.array([0.5, 0.3, 0.8]) # A target position in meters (x, y, z)\n    print(f"Attempting to move Franka end-effector to: {target_position}")\n\n    # Conceptual move command (replace with actual controller logic)\n    # franka_controller.set_end_effector_target(target_position, target_orientation)\n    # In a real scenario, you\'d loop and call the controller\'s compute_actions\n    # and then apply those actions (joint positions/velocities) to the robot.\n\n    for i in range(200): # Simulate movement over time\n        # if franka_controller.is_at_target():\n        #     print("Reached target!")\n        #     break\n        # actions = franka_controller.compute_actions(current_joint_positions, current_joint_velocities)\n        # franka.apply_action(actions)\n        if i % 50 == 0:\n            print(f"Simulating movement towards target. Step {i}...")\n        await world.render()\n        await kit.update()\n\n    print("Manipulation example complete!")\n\n    world.clear_instance()\n    kit.shutdown()\n\nif __name__ == "__main__":\n    # Isaac Sim apps often need to be run with asyncio\n    asyncio.run(run_manipulation_example())\n'})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.strong,{children:"Explanation:"})}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"Franka"}),": A pre-built robot model available in Isaac Sim."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"get_assets_root_path()"}),": Helps locate the default Isaac Sim assets."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"world.reset()"}),", ",(0,o.jsx)(n.code,{children:"world.play()"}),", ",(0,o.jsx)(n.code,{children:"world.render()"}),": Control the simulation state and rendering."]}),"\n",(0,o.jsxs)(n.li,{children:["The manipulation of robotic arms typically involves advanced controllers like ",(0,o.jsx)(n.code,{children:"RMPFlowController"})," which handle inverse kinematics and collision avoidance to move the end-effector to a desired pose (position and orientation). The provided code outlines the conceptual steps."]}),"\n"]}),"\n",(0,o.jsx)("img",{alt:"Isaac Sim Franka Arm Manipulation",src:(0,r.Ay)("/img/isaac_sim_franka_manipulation.png")}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Simulation Screenshot Placeholder:"})," A screenshot from Isaac Sim showing the Franka Emika Panda robot arm reaching towards a target or grasping an object."]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise:"})," Integrate the ",(0,o.jsx)(n.code,{children:"RMPFlowController"})," from ",(0,o.jsx)(n.code,{children:"omni.isaac.franka.controllers"})," into the example. Define a specific target position and orientation for the end-effector and observe the robot moving to that pose."]}),"\n",(0,o.jsx)(n.h2,{id:"viva-questions--answers",children:"Viva Questions & Answers"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," What Python module is primarily used to interact with the Isaac Sim environment?\n",(0,o.jsx)(n.strong,{children:"A:"})," ",(0,o.jsx)(n.code,{children:"omni.isaac.core"}),".\n",(0,o.jsx)(n.strong,{children:"Roman Urdu:"})," Isaac Sim environment ke sath interact karne ke liye bunyadi taur par kaun sa Python module istemal hota hai? ",(0,o.jsx)(n.code,{children:"omni.isaac.core"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," How do you enable and capture ground truth data from sensors like cameras in Isaac Sim?\n",(0,o.jsx)(n.strong,{children:"A:"})," Using the ",(0,o.jsx)(n.code,{children:"SyntheticDataHelper"})," class.\n",(0,o.jsx)(n.strong,{children:"Roman Urdu:"})," Isaac Sim mein sensors jaise cameras se ground truth data ko kaise enable aur capture kiya jata hai? ",(0,o.jsx)(n.code,{children:"SyntheticDataHelper"})," class ka istemal karte hue."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," What is an ",(0,o.jsx)(n.code,{children:"Articulation"})," object used for in ",(0,o.jsx)(n.code,{children:"omni.isaac.core"}),"?\n",(0,o.jsx)(n.strong,{children:"A:"})," It represents a multi-body robot with joints, allowing for control over its kinematic and dynamic properties.\n",(0,o.jsx)(n.strong,{children:"Roman Urdu:"})," ",(0,o.jsx)(n.code,{children:"omni.isaac.core"})," mein ",(0,o.jsx)(n.code,{children:"Articulation"})," object kis maqsad ke liye istemal hota hai? Yeh joints ke sath ek multi-body robot ko represent karta hai, jo uski kinematic aur dynamic properties par control ki ijazat deta hai."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," What is the common approach for controlling a robotic arm's end-effector to reach a target pose in Isaac Sim?\n",(0,o.jsx)(n.strong,{children:"A:"})," Using an Inverse Kinematics (IK) controller, such as ",(0,o.jsx)(n.code,{children:"RMPFlowController"}),", to compute joint commands.\n",(0,o.jsx)(n.strong,{children:"Roman Urdu:"})," Isaac Sim mein robotic arm ke end-effector ko target pose tak pohnchane ke liye aam tareeqa kya hai? Inverse Kinematics (IK) controller, jaise ",(0,o.jsx)(n.code,{children:"RMPFlowController"}),", ka istemal karna joint commands ko compute karne ke liye."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Q:"})," Why is it important to use ",(0,o.jsx)(n.code,{children:"world.step(render=True)"})," or ",(0,o.jsx)(n.code,{children:"await world.render()"})," in Isaac Sim scripts?\n",(0,o.jsx)(n.strong,{children:"A:"})," These calls advance the simulation by one step and ensure that the scene is rendered, allowing sensor data to be captured and visual updates to occur.\n",(0,o.jsx)(n.strong,{children:"Roman Urdu:"})," Isaac Sim scripts mein ",(0,o.jsx)(n.code,{children:"world.step(render=True)"})," ya ",(0,o.jsx)(n.code,{children:"await world.render()"})," ka istemal karna kyun zaroori hai? Yeh calls simulation ko ek step aage badhate hain aur yeh yaqeeni banate hain ke scene render ho, jis se sensor data capture kiya ja sake aur visual updates ho saken."]}),"\n"]}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(m,{...e})}):m(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>s});var i=a(6540);const o={},t=i.createContext(o);function r(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);