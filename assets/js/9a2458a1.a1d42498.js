"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[6494],{1663:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>r,default:()=>p,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"module4-RAG Systems/data-ingestion","title":"Module 4.2: Data Ingestion and Processing","description":"The foundation of any effective RAG system is its knowledge base. To build this, we must first ingest and process data from various sources. This involves identifying files, parsing their content, and preparing them for the next stage: embedding.","source":"@site/docs/module4-RAG Systems/2-data-ingestion.mdx","sourceDirName":"module4-RAG Systems","slug":"/module4-RAG Systems/data-ingestion","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module4-RAG Systems/data-ingestion","draft":false,"unlisted":false,"editUrl":"https://github.com/ShumailaWaheed/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/edit/main/docs/module4-RAG Systems/2-data-ingestion.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Module 4.2: Data Ingestion and Processing"},"sidebar":"tutorialSidebar","previous":{"title":"NVIDIA Isaac Platform Overview","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module3-NVIDIA Isaac/module3_overview"},"next":{"title":"Module 4.3: Metadata and Embeddings","permalink":"/Physical-AI-Humanoid-Robotics-A-Comprehensive-Textbook/docs/module4-RAG Systems/metadata-and-embeddings"}}');var o=t(4848),s=t(8453);const a={sidebar_position:2,title:"Module 4.2: Data Ingestion and Processing"},r="Module 4.2: Data Ingestion and Processing",d={},l=[{value:"Handling Different File Types",id:"handling-different-file-types",level:2},{value:"Indexing a Directory",id:"indexing-a-directory",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"module-42-data-ingestion-and-processing",children:"Module 4.2: Data Ingestion and Processing"})}),"\n",(0,o.jsx)(n.p,{children:"The foundation of any effective RAG system is its knowledge base. To build this, we must first ingest and process data from various sources. This involves identifying files, parsing their content, and preparing them for the next stage: embedding."}),"\n",(0,o.jsx)(n.h2,{id:"handling-different-file-types",children:"Handling Different File Types"}),"\n",(0,o.jsxs)(n.p,{children:["A robust RAG system should handle multiple document formats, as knowledge is often stored in various types of files. Common formats include plain text (",(0,o.jsx)(n.code,{children:".txt"}),"), Markdown (",(0,o.jsx)(n.code,{children:".md"}),"), PDFs (",(0,o.jsx)(n.code,{children:".pdf"}),"), and more. We can design a system that identifies the file type and uses a specific parser for each."]}),"\n",(0,o.jsx)(n.p,{children:"Here's a conceptual Python implementation for a file-handling mechanism:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'from enum import Enum\nfrom pathlib import Path\nimport fitz  # PyMuPDF for PDFs\n\nclass FileType(Enum):\n    TEXT = ".txt"\n    MARKDOWN = ".md"\n    PDF = ".pdf"\n    DOCX = ".docx"\n    UNSUPPORTED = ""\n\ndef get_file_type(file_path: Path) -> FileType:\n    """Determines the file type based on its extension."""\n    suffix = file_path.suffix.lower()\n    for file_type in FileType:\n        if suffix == file_type.value:\n            return file_type\n    return FileType.UNSUPPORTED\n\ndef read_file_content(file_path: Path) -> str:\n    """Reads the content of a file based on its type."""\n    file_type = get_file_type(file_path)\n    try:\n        if file_type == FileType.TEXT or file_type == FileType.MARKDOWN:\n            with open(file_path, \'r\', encoding=\'utf-8\') as f:\n                return f.read()\n        elif file_type == FileType.PDF:\n            with fitz.open(file_path) as doc:\n                return "".join(page.get_text() for page in doc)\n        # Add loaders for other types like DOCX here\n        else:\n            return ""  # Return empty for unsupported types\n    except Exception as e:\n        print(f"Error reading {file_path}: {e}")\n        return ""\n'})}),"\n",(0,o.jsx)(n.p,{children:"This code defines an enumeration for supported file types and provides a simple, extensible way to read content from each."}),"\n",(0,o.jsx)(n.h2,{id:"indexing-a-directory",children:"Indexing a Directory"}),"\n",(0,o.jsx)(n.p,{children:'To build our knowledge base, we need a process that recursively scans a directory, identifies supported files, reads their content, and prepares them for embedding. This "indexing" process is the first step in populating our vector database.'}),"\n",(0,o.jsx)(n.p,{children:"The function below outlines how you might structure an indexer. It would iterate through a directory and, for each file, extract its content and associate it with a unique ID and its file path."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import uuid\nfrom pathlib import Path\n\ndef index_directory(directory_path: str):\n    """\n    Recursively finds all supported files in a directory, reads their content,\n    and prepares them for embedding.\n    """\n    root_path = Path(directory_path)\n    for file_path in root_path.rglob(\'*\'):\n        if file_path.is_file() and get_file_type(file_path) != FileType.UNSUPPORTED:\n            content = read_file_content(file_path)\n            if content:\n                # In the next step, we\'ll send this content to an\n                # embedding model and store it in a vector database.\n                doc_id = str(uuid.uuid4())\n                print(f"Indexed {file_path} with ID {doc_id}")\n                # For now, we just print. Later, this will involve:\n                # 1. Chunking the content.\n                # 2. Generating embeddings for each chunk.\n                # 3. Storing the chunks, embeddings, and metadata.\n\n# Example usage:\n# index_directory("./path/to/your/documents")\n'})}),"\n",(0,o.jsxs)(n.p,{children:["This data ingestion pipeline is crucial. The quality of the data we ingest and process directly impacts the performance and accuracy of our RAG system. In the next section, we will explore how to handle the ",(0,o.jsx)(n.code,{children:"content"})," we've extracted by creating embeddings and managing metadata."]})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var i=t(6540);const o={},s=i.createContext(o);function a(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);